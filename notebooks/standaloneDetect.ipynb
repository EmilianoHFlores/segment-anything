{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5n\")  # or yolov5n - yolov5x6, custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images\n",
    "#img = \"data/images/zidane.jpg\" # or file, Path, PIL, OpenCV, numpy, list\n",
    "imgpath = \"images/foto_desktop.jpeg\"\n",
    "orig_img = cv2.imread(imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_percent = 20 # percent of original size\n",
    "width = int(orig_img.shape[1] * scale_percent / 100)\n",
    "height = int(orig_img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "  \n",
    "# resize image\n",
    "img = cv2.resize(orig_img, dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "results = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# clone img\n",
    "showimg = np.copy(img)\n",
    "# Results\n",
    "for *xyxy, conf, cls in results.pandas().xyxy[0].itertuples(index=False):\n",
    "    print(f\"Predicted {cls} at {[round(elem, 2) for elem in xyxy ]} with confidence {conf:.2f}.\")\n",
    "    thickness = 1\n",
    "    showimg = cv2.rectangle(showimg, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), (0, 255, 0), thickness)\n",
    "    showimg = cv2.putText(showimg, f\"{cls} {conf:.2f}\", (int(xyxy[0]), int(xyxy[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), thickness)\n",
    "\n",
    "# Visualize on matplotlib\n",
    "plt.imshow(cv2.cvtColor(showimg, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop all figures seen and show individually\n",
    "for *xyxy, conf, cls in results.pandas().xyxy[0].itertuples(index=False):\n",
    "    print(f\"Predicted {cls} at {[round(elem, 2) for elem in xyxy ]} with confidence {conf:.2f}.\")\n",
    "    crop_img = img[int(xyxy[1]):int(xyxy[3]), int(xyxy[0]):int(xyxy[2])]\n",
    "    plt.imshow(cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
